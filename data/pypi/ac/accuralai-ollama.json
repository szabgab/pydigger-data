{
  "name": "accuralai-ollama",
  "version": "0.2.1",
  "summary": "Ollama backend adapter for the AccuralAI LLM orchestration pipeline.",
  "license": "Apache-2.0",
  "license_expression": null,
  "home_page": "https://accural-ai.web.app/",
  "home_page_source": "project_urls.homepage",
  "maintainer": null,
  "author": "AccuralAI Maintainers",
  "repository": "https://github.com/AccuralAI/accuralai-ollama",
  "repository_source": "project_urls.repository",
  "download": null,
  "download_source": null,
  "pub_date": 1769394441,
  "project_urls": {
    "repository": "https://github.com/AccuralAI/accuralai-ollama",
    "documentation": "https://accuralai.readthedocs.io/en/latest/packages/accuralai-ollama/index.html",
    "homepage": "https://accural-ai.web.app/"
  },
  "has_github_actions": true,
  "has_gitlab_pipeline": null,
  "has_dependabot": false,
  "has_pyproject_toml": true,
  "has_setup_py": false,
  "has_setup_cfg": false
}