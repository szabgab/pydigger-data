{
  "name": "mps-bitsandbytes",
  "version": "0.6.1",
  "summary": "NF4/FP4/FP8/INT8 quantization for PyTorch on Apple Silicon with Metal GPU acceleration",
  "license": null,
  "license_expression": "MIT",
  "home_page": "https://github.com/mpsops/mps-bitsandbytes",
  "home_page_source": "project_urls.homepage",
  "maintainer": null,
  "author": "imperatormk",
  "repository": "https://github.com/mpsops/mps-bitsandbytes",
  "repository_source": "project_urls.repository",
  "download": null,
  "download_source": null,
  "pub_date": 1770074327,
  "project_urls": {
    "Documentation": "https://github.com/mpsops/mps-bitsandbytes#readme",
    "Repository": "https://github.com/mpsops/mps-bitsandbytes",
    "Homepage": "https://github.com/mpsops/mps-bitsandbytes",
    "Issues": "https://github.com/mpsops/mps-bitsandbytes/issues"
  },
  "has_github_actions": false,
  "has_gitlab_pipeline": null,
  "has_dependabot": false,
  "has_pyproject_toml": true,
  "has_setup_py": true,
  "has_setup_cfg": false
}