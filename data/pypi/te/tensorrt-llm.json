{
  "name": "tensorrt-llm",
  "version": "1.3.0rc4",
  "summary": "TensorRT LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and supports state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.",
  "license": "Apache License 2.0",
  "license_expression": null,
  "home_page": "https://github.com/NVIDIA/TensorRT-LLM",
  "home_page_source": "project_urls.homepage",
  "maintainer": null,
  "author": "NVIDIA Corporation",
  "repository": "https://github.com/NVIDIA/TensorRT-LLM",
  "repository_source": "project_urls.homepage",
  "download": "https://github.com/NVIDIA/TensorRT-LLM/tags",
  "download_source": "project_urls.download",
  "pub_date": 1771361921,
  "project_urls": {
    "Homepage": "https://github.com/NVIDIA/TensorRT-LLM",
    "Download": "https://github.com/NVIDIA/TensorRT-LLM/tags"
  },
  "has_github_actions": true,
  "has_gitlab_pipeline": null,
  "has_dependabot": false,
  "has_pyproject_toml": true,
  "has_setup_py": true,
  "has_setup_cfg": false
}