{
  "name": "EGen-Core",
  "version": "1.0.1",
  "summary": "EGen-Core — The Athena Project (2025–2026). A high-performance, memory-efficient inference engine for large language models. Run 70B+ parameter models on a single 4GB GPU without quantization, distillation, or pruning. Supports layer-wise sharded inference, 4-bit/8-bit block-wise compression, multi-architecture auto-detection, and Apple Silicon (MLX) acceleration. Developed by ErebusTN.",
  "license": null,
  "license_expression": null,
  "home_page": "https://github.com/ErebusTN/EGen-Core",
  "home_page_source": "project_urls.homepage",
  "maintainer": null,
  "author": "ErebusTN",
  "repository": "https://github.com/ErebusTN/EGen-Core",
  "repository_source": "project_urls.sourcecode",
  "download": null,
  "download_source": null,
  "pub_date": 1772223139,
  "project_urls": {
    "Documentation": "https://github.com/ErebusTN/EGen-Core#readme",
    "Source Code": "https://github.com/ErebusTN/EGen-Core",
    "Bug Tracker": "https://github.com/ErebusTN/EGen-Core/issues",
    "Homepage": "https://github.com/ErebusTN/EGen-Core"
  },
  "has_github_actions": false,
  "has_gitlab_pipeline": null,
  "has_dependabot": false,
  "has_pyproject_toml": null,
  "has_setup_py": null,
  "has_setup_cfg": null
}