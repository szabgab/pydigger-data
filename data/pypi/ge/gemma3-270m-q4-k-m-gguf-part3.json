{
  "name": "gemma3-270m-q4-k-m-gguf-part3",
  "version": "1.0.0",
  "summary": "Chunk 3 of 4 for Gemma 3 270M GGUF in Q4_K_M.",
  "license": null,
  "license_expression": null,
  "home_page": "https://huggingface.co/hugginllam/gemma-3-270m-Q4_K_M-GGUF",
  "home_page_source": "project_urls.homepage",
  "maintainer": null,
  "author": "OpenAI Codex workspace packaging",
  "repository": "https://huggingface.co/hugginllam/gemma-3-270m-Q4_K_M-GGUF",
  "repository_source": "project_urls.source",
  "download": null,
  "download_source": null,
  "pub_date": 1772285819,
  "project_urls": {
    "Homepage": "https://huggingface.co/hugginllam/gemma-3-270m-Q4_K_M-GGUF",
    "Source": "https://huggingface.co/hugginllam/gemma-3-270m-Q4_K_M-GGUF"
  },
  "has_github_actions": null,
  "has_gitlab_pipeline": null,
  "has_dependabot": null,
  "has_pyproject_toml": null,
  "has_setup_py": null,
  "has_setup_cfg": null
}